{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udf0d EO Course \u2013 Remote Sensing and Image Analysis in Space Technology","text":"<p>Welcome to the Earth Observation (EO) Course, where we explore modern techniques in remote sensing, satellite image processing, and geospatial analysis. This course focuses on practical applications using optical and SAR data, with an emphasis on cloud computing and Python-based processing instead of traditional GIS methods.  </p>"},{"location":"#course-overview","title":"\ud83d\udccc Course Overview","text":"<p>Throughout the semester, students will: \u2705 Learn SAR and optical remote sensing using multispectral and hyperspectral data. \u2705 Process and analyze Sentinel-1, Sentinel-2, and other EO datasets. \u2705 Work with Google Earth Engine (GEE), Python libraries (geemap, rasterio, xarray), and STAC-based EO data management. \u2705 Develop semester projects in teams, focusing on real-world EO applications.  </p>"},{"location":"#semester-projects","title":"\ud83d\ude80 Semester Projects","text":"<p>Students will work in teams of two (or three if needed) on research projects. Each team must: \ud83d\udd39 Maintain a GitHub repository and a GitHub Pages site for documentation. \ud83d\udd39 Present findings at the VIIIth Space Resources Conference in May 2025. \ud83d\udd39 Prepare a scientific poster summarizing their work.  </p> <p>\ud83d\udccc See project topics </p>"},{"location":"#tools-technologies","title":"\ud83d\udee0\ufe0f Tools &amp; Technologies","text":"<p>\ud83d\udd39 Python \u2013 geemap, rasterio, xarray, geopandas \ud83d\udd39 Google Earth Engine (GEE) \u2013 Cloud-based satellite data processing \ud83d\udd39 QGIS \u2013 Geospatial visualization \ud83d\udd39 Jupyter Notebook / Google Colab \u2013 Interactive coding environment \ud83d\udd39 GitHub &amp; GitHub Pages \u2013 Version control and project documentation  </p>"},{"location":"#important-dates","title":"\ud83d\udcc5 Important Dates","text":"<p>\ud83d\udccc March 15, 2025 \u2013 Abstract submission for Space Resources Conference \ud83d\udccc May 21-23, 2025 \u2013 Poster presentation and project defense at AGH University  </p>"},{"location":"#contact","title":"\ud83d\udcde Contact","text":"<p>For any questions, reach out via: \ud83d\udccd Office: D-3, 1st floor, Room 1.13 \ud83d\udcde Phone: +48 12 617 57 82 \u2709\ufe0f Email: mlupa@agh.edu.pl </p> <p>\ud83d\udccc More contact details </p> <p>\ud83d\ude80 Let\u2019s explore Earth from space! \ud83c\udf0d\ud83d\udd0d  </p>"},{"location":"contact/","title":"Contact","text":"<p>\ud83c\udf10 Website</p>"},{"location":"contact/#contact-information","title":"Contact Information","text":"<p>Micha\u0142 Lupa, Ph.D.</p> <p>AGH University of Krakow Space Technology Centre </p>"},{"location":"contact/#position","title":"Position","text":"<p>Head of Earth Observation Lab </p>"},{"location":"contact/#office-location","title":"Office Location","text":"<p>\ud83d\udccd Building D-3, 1st floor, Room 1.13 </p>"},{"location":"contact/#phone","title":"Phone","text":"<p>\ud83d\udcde +48 12 617 57 82 </p>"},{"location":"contact/#email","title":"Email","text":"<p>\u2709\ufe0f mlupa@agh.edu.pl </p>"},{"location":"introduction/","title":"\ud83d\ude80 Introduction","text":""},{"location":"introduction/#remote-sensing-and-image-analysis-in-space-tech","title":"\ud83d\udef0\ufe0f Remote Sensing and Image Analysis in Space Tech","text":"<p>\ud83d\udcc4 Course Syllabus </p>"},{"location":"introduction/#goals","title":"\ud83c\udfaf Goals","text":"<p>The course aims to provide students with a comprehensive understanding of modern satellite remote sensing techniques. It covers both optical and Synthetic Aperture Radar (SAR) technologies, focusing on: - \ud83d\udef0\ufe0f Acquisition, processing, and analysis of satellite data - \ud83c\udf0d Applications in space technology, Earth observation, and geospatial analysis</p>"},{"location":"introduction/#course-overview","title":"\ud83d\udcda Course Overview","text":"<p>This course is conducted as part of the Downstream specialization within the Master's program in Space Technologies. It is divided into two sections: - \ud83d\udd35 Optical Data Processing \u2013 Led by Dr. Eng. Micha\u0142 Lupa (LinkedIn, ResearchGate) - \ud83d\udd34 Radar Data Processing \u2013 Led by Dr. Dariusz Zi\u00f3\u0142kowski (IGIK, ResearchGate)  </p>"},{"location":"introduction/#lecture-schedule","title":"\ud83d\uddd3\ufe0f Lecture Schedule","text":"<p>\ud83d\udccd Lectures are held on Wednesdays from 11:30 to 13:00 </p>"},{"location":"introduction/#optical-data-processing","title":"\ud83d\udd35 Optical Data Processing","text":"\ud83d\udcc5 Date \ud83d\udc68\u200d\ud83c\udfeb Lecturer \ud83d\uddd3\ufe0f March 5, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uddd3\ufe0f March 12, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uded1 March 19, 2025 - \ud83d\uddd3\ufe0f March 26, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uded1 April 2, 2025 - \ud83d\uddd3\ufe0f April 9, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uded1 April 16, 2025 - \ud83d\uddd3\ufe0f April 23, 2025 Dr. Eng. Micha\u0142 Lupa"},{"location":"introduction/#radar-data-processing","title":"\ud83d\udd34 Radar Data Processing","text":"\ud83d\udcc5 Date \ud83d\udc68\u200d\ud83c\udfeb Lecturer \ud83d\uddd3\ufe0f May 7, 2025 Dr. Dariusz Zi\u00f3\u0142kowski \ud83d\uded1 May 14, 2025 - \ud83d\uddd3\ufe0f May 21, 2025 Dr. Dariusz Zi\u00f3\u0142kowski \ud83d\uded1 May 28, 2025 - \ud83d\uddd3\ufe0f June 4, 2025 Dr. Dariusz Zi\u00f3\u0142kowski \ud83d\uded1 June 11, 2025 - \ud83d\uddd3\ufe0f June 18, 2025 Dr. Dariusz Zi\u00f3\u0142kowski"},{"location":"introduction/#laboratory-classes","title":"\ud83c\udfd7\ufe0f Laboratory Classes","text":"<p>\ud83d\udccd Laboratory sessions are held on Wednesdays, with two time slots: - \ud83d\udd50 Slot 1: 13:15 - 14:45 - \ud83d\udd51 Slot 2: 15:00 - 16:30  </p> <p>Each session consists of two parts with a 15-minute break: 1. \u2699\ufe0f Implementation Tasks \u2013 Students will develop practical skills in satellite data processing and analysis using specific tools and programming languages recommended by the instructor. 2. \ud83d\udef0\ufe0f Semester Project \u2013 From the first session, students will work on a semester-long project, gradually building their final deliverable.</p>"},{"location":"introduction/#laboratory-schedule","title":"\ud83d\uddd3\ufe0f Laboratory Schedule","text":"\ud83d\udcc5 Date \ud83d\udc68\u200d\ud83c\udfeb Lecturer \ud83d\uddd3\ufe0f March 5, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uddd3\ufe0f March 12, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uddd3\ufe0f March 19, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uddd3\ufe0f March 26, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uddd3\ufe0f April 2, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uddd3\ufe0f April 9, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uddd3\ufe0f April 16, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uddd3\ufe0f April 23, 2025 Dr. Eng. Micha\u0142 Lupa \ud83d\uddd3\ufe0f May 7, 2025 Dr. Dariusz Zi\u00f3\u0142kowski \ud83d\uddd3\ufe0f May 14, 2025 Dr. Dariusz Zi\u00f3\u0142kowski \ud83d\uddd3\ufe0f May 21, 2025 Dr. Dariusz Zi\u00f3\u0142kowski \ud83d\uddd3\ufe0f May 28, 2025 Dr. Dariusz Zi\u00f3\u0142kowski \ud83d\uddd3\ufe0f June 4, 2025 Dr. Dariusz Zi\u00f3\u0142kowski \ud83d\uddd3\ufe0f June 11, 2025 Dr. Dariusz Zi\u00f3\u0142kowski \ud83d\uddd3\ufe0f June 18, 2025 Dr. Dariusz Zi\u00f3\u0142kowski \ud83d\uddd3\ufe0f June 25, 2025 (It is Friday at AGH) <p>\ud83d\udccc This document provides an overview of the course structure, schedule, and expectations. Make sure to follow the course updates on GitHub and Google Colab for materials and assignments. </p> <p>\ud83d\ude80 See you in class!</p>"},{"location":"labs/","title":"Labs","text":"<p>We welcome collaborations and contributions to our projects. If you are interested in working with us or learning more, feel free to explore our repositories or reach out to us.</p>"},{"location":"projects/","title":"\ud83d\ude80 Guidelines for Semester Projects \u2013 Summer 2025","text":""},{"location":"projects/#1-general-information","title":"\ud83d\udccc 1. General Information","text":"<p>Semester projects are a key component of course assessment, carrying a weight of 0.7 in the final grade. Each project team consists of two students (except in cases of an odd number of students, where one team may have three members).  </p> <p>\ud83d\udccc Each project must have: - \ud83d\uddc2\ufe0f A dedicated GitHub repository. - \ud83c\udf10 A GitHub Pages site where data, code, documentation, sources, and bibliography will be published.  </p>"},{"location":"projects/#2-project-evaluation-conference-presentation","title":"\ud83c\udfa4 2. Project Evaluation &amp; Conference Presentation","text":"<p>The final evaluation of the project takes place through a poster presentation at the student poster session during the VIIIth Space Resources Conference \u2013 Path to Lunar Sustainability, held on May 21-23, 2025, at AGH University of Krakow, Poland (\ud83c\udf0d spaceconf.org).  </p>"},{"location":"projects/#important-deadlines","title":"\ud83d\udcc5 Important Deadlines","text":"<ul> <li>\ud83d\udcdd March 15, 2025 \u2013 Each team must submit an abstract of their project to the conference system.  </li> <li>\ud83c\udfaf May 21-23, 2025 \u2013 Poster presentation and project defense at the conference.  </li> </ul>"},{"location":"projects/#presentation-requirements","title":"\ud83d\uddbc\ufe0f Presentation Requirements","text":"<ul> <li>Each project team must prepare a poster using Canva/Figma.  </li> <li>The poster will be presented during the conference, where the instructor and conference attendees will ask questions. Answering these questions will be considered equivalent to defending the project.  </li> <li>Each poster must include a QR code linking to the GitHub Pages site of the project.  </li> </ul>"},{"location":"projects/#3-research-groups-project-support","title":"\ud83c\udfdb\ufe0f 3. Research Groups &amp; Project Support","text":"<p>Projects must be conducted within student research groups, preferably those officially registered at the AGH Center for Space Technologies, e.g. (\ud83d\udd17 AGH STARS).</p> <p>\ud83d\udccc Being part of a research group offers students access to: - \ud83c\udf93 Expert knowledge, - \ud83d\udee0\ufe0f Specialized equipment, - \ud83d\udcb0 Funding opportunities, including field research trips.  </p>"},{"location":"projects/#4-list-of-semester-projects-summer-2025","title":"\ud83d\udcdc 4. List of Semester Projects (Summer 2025)","text":"<p>The following projects are available for selection. Click on a project title to see detailed guidelines:  </p> <ol> <li>\ud83c\udf0a Assessment of Inland Water Quality Using Optical Data and In Situ Measurements: A Case Study of Dobczyckie Lake </li> <li>\ud83c\udf31 Satellite Monitoring of Soil Moisture in Agriculture Using Optical and SAR Data </li> <li>\ud83c\udfd7\ufe0f Satellite Monitoring of Open-Pit Mining Sites Using Optical and SAR Data </li> <li>\ud83c\udf3e Satellite Monitoring of Winter Wheat Cultivation in \u015awi\u0119tokrzyskie Voivodeship (Kazimierza County, 2015\u2013Present) </li> <li>\ud83d\udc1d Optimizing Mobile Beekeeping: Satellite-Based Recommendations for Beekeepers in Nowos\u0105decki County </li> <li>\ud83d\ude9c Monitoring Soil Tillage Using Satellite Data </li> <li>\ud83c\udf0d Monitoring Bare-Soil Exposure Using Satellite Data </li> <li>\ud83e\uddea Monitoring Chlorophyll Levels in Solina Reservoir Using Sentinel Data </li> </ol>"},{"location":"projects/#5-custom-project-proposals","title":"\u2728 5. Custom Project Proposals","text":"<p>Students may propose their own project, provided that the topic is discussed and approved by the instructor during class sessions.  </p> <p>\ud83d\udccc \u2b05\ufe0f Back to Course Homepage </p>"},{"location":"research/","title":"Research","text":"<p>Our group specializes in:</p> <ul> <li>Remote Sensing &amp; Earth Observation - processing and analyzing satellite and UAV imagery for environmental monitoring,</li> <li>Geospatial Data Science - developing algorithms and workflows for spatial data processing, analysis, and visualization,</li> <li>Geospatial Infrastructure &amp; Cloud Computing - deploying scalable solutions for geospatial data storage, processing, and sharing.</li> </ul>"},{"location":"team/","title":"Team","text":"<p>Our team consists of researchers, engineers, and students passionate about geospatial technologies and environmental applications. We collaborate with academic institutions, industry partners, and government agencies to push the boundaries of Earth observation research.</p>"},{"location":"assets/labs/lab_0/","title":"\ud83d\udee0\ufe0f Lab 0: Environment Setup &amp; Configuration","text":""},{"location":"assets/labs/lab_0/#1-objective","title":"1. Objective","text":"<p>Before we start working with satellite data, we need to set up the development environment. This lab focuses on installing and configuring: \u2705 VS Code &amp; GitHub for version control. \u2705 Google Earth Engine (GEE) for satellite data processing. \u2705 Google Colab for cloud-based Python execution. \u2705 Miniconda &amp; Python libraries for geospatial analysis.  </p>"},{"location":"assets/labs/lab_0/#2-installing-the-required-tools","title":"2. Installing the Required Tools","text":""},{"location":"assets/labs/lab_0/#21-code-editor-visual-studio-code-vs-code","title":"2.1. Code Editor: Visual Studio Code (VS Code)","text":"<p>\ud83d\udccc Download &amp; Install VS Code: VS Code Download </p> <p>After installation, install the following extensions: - Python Extension \u2013 Enables Python scripting. - Jupyter Extension \u2013 Enables Jupyter Notebook inside VS Code. - GitHub Copilot (Optional) \u2013 AI-powered code assistance.  </p>"},{"location":"assets/labs/lab_0/#22-git-github-setup","title":"2.2. Git &amp; GitHub Setup","text":"<p>We will use GitHub for project version control.  </p> <p>\ud83d\udccc Download &amp; Install Git: Git Download </p> <p>\ud83d\udccc Set up GitHub (if you don\u2019t have an account, create one at GitHub):  </p> <pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n</code></pre>"},{"location":"assets/labs/lab_0/#3-setting-up-python-miniconda","title":"3. Setting Up Python &amp; Miniconda","text":""},{"location":"assets/labs/lab_0/#31-install-miniconda","title":"3.1. Install Miniconda","text":"<p>\ud83d\udccc Download Miniconda: Miniconda Download </p> <p>\ud83d\udccc Create and activate an environment for the course: <pre><code>conda create -n eo_lab python=3.9\nconda activate eo_lab\n</code></pre></p> <pre><code>pip install geemap earthengine-api jupyterlab geopandas rasterio matplotlib numpy\n</code></pre>"},{"location":"assets/lectures/lecture_1/","title":"\ud83d\udef0\ufe0f Lecture 1: Fundamentals of Remote Sensing","text":""},{"location":"assets/lectures/lecture_1/#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":"<p>By the end of this lecture, you will understand:  </p> <ul> <li>What is Remote Sensing and its importance in Earth observation  </li> <li>The role of electromagnetic radiation (EMR) in remote sensing  </li> <li>How the atmosphere affects remote sensing data </li> <li>The difference between passive and active remote sensing systems </li> <li>Key imaging properties, including spatial, spectral, radiometric, and temporal resolution  </li> </ul>"},{"location":"assets/lectures/lecture_1/#lecture-topics-overview","title":"\ud83d\udccc Lecture Topics Overview","text":"<p>1\ufe0f\u20e3 What is Remote Sensing? 2\ufe0f\u20e3 Electromagnetic Radiation (EMR) 3\ufe0f\u20e3 Atmospheric Effects 4\ufe0f\u20e3 Passive vs. Active Imaging 5\ufe0f\u20e3 Resolutions - Imaging Properties </p>"},{"location":"assets/lectures/lecture_1/#1-what-is-remote-sensing-1-what-is-remote-sensing","title":"1. What is Remote Sensing? {#1-what-is-remote-sensing} \ud83c\udf0d","text":"<p>Remote sensing is the process of collecting information about objects from a distance, without the need for physical contact. It is both a science and an art, as it involves obtaining and interpreting data about an object, area, or phenomenon through measurements made by instruments that are not in direct contact with the subject (Lillesand et al., 2015).  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#11-detecting-light","title":"1.1 Detecting Light","text":"<p>A simple example of remote sensing is human vision. Our eyes detect red, green, and blue light, and our brain processes these signals into the full range of visible colors. Artificial remote sensing systems, such as cameras, satellites, and sensors, work in a similar way\u2014by detecting and interpreting different wavelengths of electromagnetic radiation.  </p>"},{"location":"assets/lectures/lecture_1/#12-how-remote-sensing-works","title":"1.2 How Remote Sensing Works","text":"<p>Remote sensing allows scientists to monitor and analyze Earth\u2019s surface and atmosphere by measuring the reflected or emitted radiation from various objects. Drones, airplanes, and satellites equipped with specialized sensors capture this energy and translate it into usable data.  </p> <p>Depending on the application, remote sensing sensors collect data across different parts of the electromagnetic spectrum and at various levels of resolution. This helps in characterizing different land areas, water bodies, and atmospheric conditions.  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#13-essential-elements-of-remote-sensing","title":"1.3 Essential Elements of Remote Sensing","text":"<p>To perform remote sensing, three key components are required:  </p> <p>a. A platform \u2013 A carrier for the sensor, such as a satellite, drone, or aircraft. b. A target \u2013 The object or area being observed (e.g., land surface, ocean, clouds). 3c. An instrument \u2013 A sensor designed to detect and capture specific types of energy.  </p> <p>These instruments analyze different energy sources and provide insights into environmental changes, land cover, vegetation health, and more.  </p>"},{"location":"assets/lectures/lecture_1/#2-remote-sensing-platforms-2-remote-sensing-platforms","title":"2. Remote Sensing Platforms {#2-remote-sensing-platforms}","text":"<p>Remote sensing platforms refer to the carriers that house cameras or sensors for data collection. These platforms can be stationary (e.g., cameras on tripods) or mobile (e.g., drones, aircraft, satellites). The choice of platform significantly affects the type, scale, and frequency of collected imagery.  </p>"},{"location":"assets/lectures/lecture_1/#21-types-of-remote-sensing-platforms","title":"2.1 Types of Remote Sensing Platforms","text":""},{"location":"assets/lectures/lecture_1/#a-ground-based-platforms","title":"a. Ground-Based Platforms","text":"<ul> <li>Tripods, towers, and vehicles equipped with sensors for close-range remote sensing.  </li> </ul>"},{"location":"assets/lectures/lecture_1/#b-aerial-platforms","title":"b. Aerial Platforms","text":"<ul> <li>Drones, airplanes, or balloons that operate within the atmosphere, capturing medium-scale imagery.  </li> </ul>"},{"location":"assets/lectures/lecture_1/#c-satellite-platforms","title":"c. Satellite Platforms","text":"<ul> <li>Orbiting satellites providing large-scale, repetitive coverage of Earth's surface.  </li> </ul>"},{"location":"assets/lectures/lecture_1/#22-cost-vs-coverage-trade-off","title":"2.2 Cost vs. Coverage Trade-off","text":"<p>As a general rule, higher altitude platforms tend to be more expensive but cover larger areas more efficiently.  </p> <ul> <li>A handheld camera is inexpensive but impractical for imaging large areas.  </li> <li>A drone can capture high-resolution imagery at a regional scale.  </li> <li>A satellite is costly to launch and maintain but can continuously monitor vast portions of the planet.  </li> </ul> <p>Resolution Considerations The farther a platform is from Earth, the lower the spatial resolution tends to be. This means that each pixel in the image represents a larger surface area on Earth.  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#3-electromagnetic-waves-3-electromagnetic-waves","title":"3. Electromagnetic Waves {#3-electromagnetic-waves}","text":"<p>The application of remote sensing sensors and methods relies on the existence of electromagnetic (EM) radiation. Whether the radiation is passively measured (e.g., reflection of sunlight) or actively emitted from an instrument, remote sensing cannot function without this source of energy.  </p> <p>But what exactly are waves?  </p> <p>A wave is an undulating motion that transports energy in the direction of its propagation. A simple example of natural waves can be seen in water waves forming after a stone is thrown into a pond. Similarly, sound waves are created when we speak or when a police siren passes by.  </p>"},{"location":"assets/lectures/lecture_1/#31-electromagnetic-wave-structure","title":"3.1 Electromagnetic Wave Structure","text":"<p>Radiation from the Sun travels in the form of electromagnetic waves, where electric and magnetic fields are coupled together.  </p> <p>An electromagnetic wave consists of two perpendicular components: - An electric field (E, blue) - A magnetic field (B, red) </p> <p>The electric field oscillates in one plane, while the magnetic field oscillates at a right angle to it. Both fields propagate at the speed of light (~300,000 km/s).  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#32-wave-characteristics","title":"3.2 Wave Characteristics","text":"<p>Electromagnetic waves are described by three fundamental properties:  </p> <p>a. Frequency (\u03bd) \u2013 The number of wave cycles (marked by crests) that pass a point in a given time (usually per second). b. Wavelength (\u03bb) \u2013 The distance between two successive crests of a wave.    - Wavelength and frequency are inversely proportional:      - Higher frequency \u2192 shorter wavelength      - Lower frequency \u2192 longer wavelength c. Amplitude (A) \u2013 The height of the wave from its rest position to the crest (top) or trough (bottom).    - Intensity (important in remote sensing) is proportional to the square of the amplitude.  </p> <p>The relationship between these properties can be expressed as: [ \\text{frequency} = \\frac{\\text{speed of light}}{\\text{wavelength}} ]</p>"},{"location":"assets/lectures/lecture_1/#33-energy-and-wavelength","title":"3.3 Energy and Wavelength","text":"<p>The energy of a wave is directly related to its frequency:  </p> <ul> <li>Higher frequency = more energy </li> <li>Lower frequency = less energy </li> </ul> <p>Thus, waves with longer wavelengths carry less energy, while short-wavelength waves (like X-rays) carry more energy.  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#34-the-spectrum-of-electromagnetic-radiation","title":"3.4 The Spectrum of Electromagnetic Radiation","text":"<p>Electromagnetic energy travels in waves and spans a broad spectrum ranging from very long radio waves to very short gamma rays. The human eye can detect only a small portion of this spectrum, known as visible light.  </p> <p>Other devices, such as radios, X-ray machines, and scientific instruments used in remote sensing, are capable of detecting different regions of the electromagnetic spectrum (EMS). These instruments allow scientists to study not only Earth but also the solar system and even the universe beyond.  </p>"},{"location":"assets/lectures/lecture_1/#341-electromagnetic-spectrum-overview","title":"3.4.1 Electromagnetic Spectrum Overview","text":"<p>The figure below illustrates the different regions of the electromagnetic spectrum, including their: - Names (radio waves, microwaves, infrared, visible light, ultraviolet, X-rays, gamma rays) - Wavelengths (measured in meters, micrometers, or nanometers) - Frequencies (measured in Hertz) - Energy levels </p> <p>It also highlights the scale of objects that can interact with each wavelength and the biological or environmental influences of different EM radiation types.  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#342-wavelength-frequency-and-energy-relationship","title":"3.4.2 Wavelength, Frequency, and Energy Relationship","text":"<p>Now that we have discussed the fundamental properties of EM waves, we can explore how photons are distributed along the electromagnetic spectrum (EMS).  </p> <p>We know that: - Wavelength and frequency are inversely related (shorter wavelength = higher frequency). - Photon energy increases as wavelength decreases.  </p>"},{"location":"assets/lectures/lecture_1/#blackbody-radiation-and-temperature-dependence","title":"Blackbody Radiation and Temperature Dependence","text":"<p>The temperature of an object affects the wavelength of radiation it emits. The figure above also demonstrates this using a thermometer, which shows that: - Hotter objects emit shorter wavelengths of radiation. - Cooler objects emit longer wavelengths of radiation.  </p> <p>This relationship follows Planck's Law, which describes the emission of electromagnetic radiation from an idealized blackbody. A blackbody is a theoretical object that absorbs all incoming radiation and emits energy based purely on its temperature.  </p> <p>For example: - The Sun (5788 K) emits most of its radiation at ~0.5 \u00d7 10\u207b\u2076 m (500 nm, visible light). - The human body (~310 K) emits most of its radiation at ~10\u207b\u2074 m (infrared range, ~10 \u00b5m).  </p> <p>\ud83d\udccc Important Note: In reality, blackbodies do not exist\u2014real-world objects always emit slightly less radiation than a perfect blackbody at the same temperature.  </p>"},{"location":"assets/lectures/lecture_1/#343-the-primary-source-of-electromagnetic-radiation-53-the-primary-source-of-electromagnetic-radiation","title":"3.4.3 The Primary Source of Electromagnetic Radiation {#53-the-primary-source-of-electromagnetic-radiation}","text":"<p>The primary source of energy received on Earth is electromagnetic radiation emitted from the Sun.  </p> <p>The Sun\u2019s radiation is reflected and absorbed by the Earth's atmosphere and surface. Satellites carry instruments that measure the electromagnetic radiation reflected or emitted.  </p> <p> </p> <p>The Sun emits most of its energy at optical wavelengths, between 0.1 \u00b5m to 4 \u00b5m. Solar energy, frequently referred to as shortwave radiation, includes ultraviolet, visible, and infrared radiation. In Earth satellite remote sensing, we are mostly concerned with wavelengths from ultraviolet (0.1 \u00b5m) through the microwave (100,000 \u00b5m).  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#344-absorption-in-the-atmosphere","title":"3.4.4 Absorption in the Atmosphere","text":"<p>Understanding where our atmosphere absorbs different parts of the electromagnetic radiation (EMR) is crucial for interpreting signals received by remote sensing instruments.  </p> <p>A key distinction between atmospheric absorption and scattering is the effective energy loss to atmospheric constituents. In absorption, energy is directly transferred into molecules in the atmosphere or to the remote sensing targets.  </p> <p>Certain gases in the atmosphere, such as: - Ozone (O\u2083) - Carbon dioxide (CO\u2082) - Water vapor (H\u2082O) </p> <p>can absorb energy and contribute to warming the planet.</p> <p>When electromagnetic waves interact with different materials, they exhibit predictable behaviors:  </p> <p>a. Reflection \u2013 The wave bounces off a surface (important for optical remote sensing). b. Absorption \u2013 The wave's energy is absorbed by the material. c. Scattering \u2013 The wave changes direction randomly (e.g., atmospheric scattering). d. Transmission \u2013 The wave passes through the material without being absorbed. e. Emission &amp; Re-emission \u2013 The material releases stored energy as electromagnetic radiation.  </p> <p>These behaviors are critical in remote sensing, as they determine how energy interacts with Earth's surface and atmosphere, affecting how we interpret satellite imagery.  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#3441-atmospheric-windows","title":"3.4.4.1 Atmospheric Windows","text":"<p>From a remote sensing perspective, the goal is to use wavelengths that avoid strong absorption regions in the atmosphere.  </p> <p>\ud83d\udccc Where the atmosphere is highly transmissive to incoming wavelengths, we call these regions \"atmospheric windows\". </p> <p>The brown curve in the diagram below represents the opaqueness of the atmosphere.  </p> <ul> <li>The big atmospheric windows between 1 mm and 1 m allow us to operate microwave remote sensing systems (e.g., radar sensors).  </li> <li>In contrast, atmospheric windows in the multispectral portions of the EM spectrum are much narrower.  </li> </ul> <p> </p>"},{"location":"assets/lectures/lecture_1/#3442-selecting-the-right-remote-sensing-instrument","title":"3.4.4.2 Selecting the Right Remote Sensing Instrument","text":"<p>When designing or choosing remote sensing sensors, it is essential to carefully consider the following three questions:  </p> <ol> <li>What is the spectral sensitivity of my sensor? </li> <li> <p>Does my sensor operate in a wavelength range affected by atmospheric absorption?  </p> </li> <li> <p>Which atmospheric windows can be used with this sensor? </p> </li> <li> <p>Is my sensor designed to work in regions of high transmissivity?  </p> </li> <li> <p>What is the source, magnitude, and composition of the outgoing signal we are aiming to analyze? </p> </li> <li>How does the atmosphere influence the signal we receive?  </li> </ol> <p>Selecting an appropriate sensor and understanding atmospheric absorption is critical to ensuring the accuracy of Earth observation data.  </p>"},{"location":"assets/lectures/lecture_1/#3445-why-is-this-important-for-remote-sensing","title":"3.4.4.5 Why Is This Important for Remote Sensing?","text":"<p>Understanding the electromagnetic spectrum is crucial for remote sensing because: a. Different materials interact with specific wavelengths of radiation. b. Sensors are designed to detect radiation at different frequencies (e.g., infrared for vegetation, microwaves for weather radar). c. The Earth's atmosphere absorbs certain wavelengths while allowing others to pass through (this is why certain satellites use infrared or microwave sensors to \"see\" through clouds).  </p> <p>This knowledge allows us to design specialized remote sensing instruments for applications such as: \ud83c\udf31 Vegetation monitoring (infrared and near-infrared reflectance) \ud83c\udfd9\ufe0f Urban mapping (visible and shortwave infrared) \ud83c\udf0a Water quality assessment (UV and visible light absorption) \ud83c\udf0e Climate studies (microwave and infrared radiation)  </p>"},{"location":"assets/lectures/lecture_1/#4-spectral-signatures-4-spectral-signatures","title":"4. Spectral Signatures {#4-spectral-signatures}","text":""},{"location":"assets/lectures/lecture_1/#41-what-are-spectral-signatures-41-what-are-spectral-signatures","title":"4.1 What are Spectral Signatures? {#41-what-are-spectral-signatures}","text":"<p>Different wavelengths of the electromagnetic spectrum interact differently with various materials on Earth's surface and in the atmosphere.  </p> <p>Certain materials and physical properties have a unique way of interacting with incident radiation. This interaction is called the spectral response\u2014how the material reflects, absorbs, or emits radiation.  </p> <p>\ud83d\udccc The spectral response of an object is known as its spectral signature. </p> <p>For example: - Some materials have a higher reflectance at specific wavelengths. - The percent reflectance is the ratio of reflected energy to the total incident energy at a given wavelength.  </p>"},{"location":"assets/lectures/lecture_1/#key-concepts","title":"Key Concepts","text":"<p>a. Radiance: A measure of the power of electromagnetic radiation emitted from an object per unit area for a given wavelength. In the visible spectrum, radiance is also described as the brightness of the source. It is directly proportional to amplitude (and intensity) of the wave.  </p> <p>Surfaces do not only reflect light; they also partially absorb it.  </p> <p>During absorption, energy is taken up by the molecules of a material and transformed into kinetic energy. This increased molecular movement produces heat, which is radiated back to the surroundings.  </p> <p>Example: A black t-shirt absorbs more sunlight than a white t-shirt, which is why we feel hotter wearing black in summer.  </p> <p>Albedo measures the reflective properties of materials across different spectral ranges: - Albedo = 100% \u2192 No absorption, full reflection. - Albedo = 0% \u2192 No reflection, full absorption.  </p> Material Albedo (%) Snow 80-90% Cloud 60-90% Sand 30% Meadow 20% Forest 5-18% Concrete 15% Water (low angle) 22% Water (high angle) 5% <p></p> <p>Surface Albedo: The fraction of incident radiation that is reflected by the Earth's surface for a given location and time.  </p>"},{"location":"assets/lectures/lecture_1/#42-types-of-reflection-42-types-of-reflection","title":"4.2 Types of Reflection {#42-types-of-reflection}","text":"<p>The way electromagnetic waves interact with surfaces depends on their roughness. There are three main types of reflection:  </p> <p></p>"},{"location":"assets/lectures/lecture_1/#1-specular-reflection-mirror-like","title":"1. Specular Reflection (Mirror-like)","text":"<ul> <li>Occurs when light strikes a smooth surface.  </li> <li>The angle of incidence is equal to the angle of reflection.  </li> <li>Example: Glass, still water, metal surfaces.  </li> </ul>"},{"location":"assets/lectures/lecture_1/#2-diffuse-reflection","title":"2. Diffuse Reflection","text":"<ul> <li>Happens on rough surfaces, scattering light in all directions.  </li> <li>No clear angle of reflection.  </li> <li>Example: Concrete, vegetation, unpolished wood.  </li> </ul>"},{"location":"assets/lectures/lecture_1/#3-mixed-reflection","title":"3. Mixed Reflection","text":"<ul> <li>The most common type in nature.  </li> <li>A combination of specular and diffuse reflection.  </li> <li>Example: Most natural surfaces like soil, rocks, leaves.  </li> </ul>"},{"location":"assets/lectures/lecture_1/#43-remote-sensing-and-spectral-signatures-43-remote-sensing-and-spectral-signatures","title":"4.3 Remote Sensing and Spectral Signatures {#43-remote-sensing-and-spectral-signatures}","text":"<p>Remote sensors are designed to detect wavelengths in particular parts of the electromagnetic spectrum. These instruments help identify objects or materials based on their spectral signatures.  </p> <p>Let's examine how different materials on Earth interact with electromagnetic radiation and define their unique spectral signatures:  </p> <p></p>"},{"location":"assets/lectures/lecture_1/#1-vegetation","title":"1. Vegetation","text":"<ul> <li>Plants absorb blue and red light due to photosynthesis.  </li> <li>Peak reflectance occurs in the green region (which is why plants appear green).  </li> <li>Near-infrared (NIR) reflectance is much higher than in the visible spectrum.  </li> </ul>"},{"location":"assets/lectures/lecture_1/#2-water","title":"2. Water","text":"<ul> <li>Clear water absorbs most radiation, appearing dark.  </li> <li>Turbid water reflects more light.  </li> <li>Algal blooms increase green reflectance.  </li> </ul>"},{"location":"assets/lectures/lecture_1/#3-soil","title":"3. Soil","text":"<ul> <li>Soil moisture content impacts its spectral signature.  </li> <li>Dry soil has higher reflectance than wet soil.  </li> </ul>"},{"location":"assets/lectures/lecture_1/#4-ice-snow","title":"4. Ice &amp; Snow","text":"<ul> <li>Fresh snow has high reflectance across the visible and NIR regions.  </li> <li>Aged or dirty snow absorbs more radiation, lowering reflectance.  </li> </ul>"},{"location":"assets/lectures/lecture_1/#atmosphere","title":"\u2601\ufe0f Atmosphere","text":"<ul> <li>Atmospheric gases and particles scatter and absorb certain wavelengths.  </li> <li>Clouds reflect visible light, making them bright in satellite imagery.  </li> </ul> <p>\ud83d\udccc Understanding atmospheric interference is crucial for interpreting remote sensing data correctly.</p>"},{"location":"assets/lectures/lecture_1/#44-using-spectral-signatures-to-distinguish-materials-44-using-spectral-signatures-to-distinguish-materials","title":"4.4 Using Spectral Signatures to Distinguish Materials {#44-using-spectral-signatures-to-distinguish-materials}","text":"<p>Each material absorbs and reflects different wavelengths of electromagnetic radiation.  </p> <p>The graph below compares reflectance values across various materials:  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#45-how-to-measure-spectral-signature-46-how-to-measure-spectral-signature","title":"4.5 How to Measure Spectral Signature? {#46-how-to-measure-spectral-signature}","text":"<p>To analyze spectral signatures, scientists use specialized instruments that measure the reflectance, absorption, and emission properties of different materials. There are two main approaches to measuring spectral signatures:  </p>"},{"location":"assets/lectures/lecture_1/#451-field-measurements-using-a-spectroradiometer","title":"4.5.1 Field Measurements Using a Spectroradiometer","text":"<p>A spectroradiometer is an instrument used in field conditions to measure how different surfaces interact with light. These devices capture spectral signatures of vegetation, soil, water, and other materials directly in their natural environment.  </p> <p>\ud83d\udccc Example: Measuring Spectral Signatures of Vegetation - Used to analyze plant health, chlorophyll content, and stress levels. - Helps monitor photosynthetic activity by measuring near-infrared (NIR) reflectance. - Data is used in applications like precision agriculture, ecosystem monitoring, and climate studies.  </p> <p>\ud83d\udd0d Field Measurement Example: </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#452-laboratory-measurements-using-a-hyperspectral-camera","title":"4.5.2 Laboratory Measurements Using a Hyperspectral Camera","text":"<p>In controlled laboratory environments, hyperspectral cameras capture spectral signatures with high precision. These cameras analyze light interactions across hundreds of spectral bands, allowing for highly detailed material classification.  </p> <p>\ud83d\udccc Example: Measuring Spectral Properties of Samples in a Lab - Used for soil, minerals, plant samples, and industrial materials. - Provides high spectral resolution for material classification and chemical analysis. - Used in geology, material science, agriculture, and environmental monitoring.  </p> <p>\ud83d\udd0d Hyperspectral Imaging Examples: </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#why-is-spectral-signature-measurement-important","title":"Why Is Spectral Signature Measurement Important?","text":"<ol> <li>Distinguishing materials based on their spectral properties </li> <li>Identifying plant stress, soil moisture, or water quality changes </li> <li>Enhancing remote sensing applications in agriculture, geology, and climate science </li> <li>Calibrating satellite and airborne remote sensing data for improved accuracy </li> </ol>"},{"location":"assets/lectures/lecture_1/#5-passive-vs-active-imaging-5-passive-vs-active-imaging","title":"5. Passive vs. Active Imaging {#5-passive-vs-active-imaging}","text":""},{"location":"assets/lectures/lecture_1/#51-passive-vs-active-sensors","title":"5.1 Passive vs. Active Sensors","text":"<p>The way a remote sensing sensor captures energy is categorized as either passive or active.  </p> <p>Remote sensors detect electromagnetic radiation to identify physical characteristics of an object. They either: a. Use an external source of radiation, most often the Sun (passive sensors). b. Transmit their own energy toward the object and measure the return (active sensors).  </p> <p> </p> <p>\ud83d\udccc Comparison of Passive and Active Sensors: </p> Sensor Type Energy Source Day/Night Operation Weather Dependency Example Applications Passive External (e.g., Sun) Limited at night Can be affected by clouds Optical imagery, thermal sensing, vegetation health Active Own energy source Works day &amp; night Can operate in all weather conditions Radar, LiDAR, altimetry"},{"location":"assets/lectures/lecture_1/#52-daytime-dependence-of-passive-sensors","title":"5.2 Daytime Dependence of Passive Sensors","text":""},{"location":"assets/lectures/lecture_1/#521-the-role-of-natural-radiation","title":"5.2.1 The Role of Natural Radiation","text":"<p>Passive remote sensing relies solely on naturally occurring radiation, primarily from the Sun. Unlike active sensors, passive instruments do not emit their own pulses of electromagnetic energy. This means that: - Passive optical sensors can only acquire data during the day. - Without natural light, no radiation is reflected back to the sensor, rendering nighttime imaging impossible (except in thermal infrared). - Atmospheric conditions (e.g., cloud cover, haze) affect the amount of sunlight reaching the Earth's surface, which in turn impacts image quality.  </p> <p>However, some passive sensors can operate at night\u2014for example, thermal infrared scanners that measure the heat emitted from objects rather than reflected sunlight.  </p> <p>\ud83d\udccc Illustration: Conceptual operation of passive and active remote sensing instruments </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#53-active-sensors","title":"5.3 Active Sensors","text":"<p>Active sensors generate and transmit their own energy toward a target, then detect the reflected or scattered return signal.  </p> <p>a. Advantages of Active Sensors: - Work independently of sunlight \u2192 Can operate day and night. - Can penetrate clouds, smoke, and even vegetation canopies (especially radar-based sensors). - Provide 3D surface mapping capabilities (e.g., LiDAR, radar altimetry).  </p> <p>b. Examples of Active Sensors: - Radar (Synthetic Aperture Radar - SAR) \u2013 Used for Earth surface monitoring and disaster response. - LiDAR (Light Detection and Ranging) \u2013 High-precision elevation mapping. - Altimeters \u2013 Measure ocean height and ice sheet thickness.  </p>"},{"location":"assets/lectures/lecture_1/#54-types-of-passive-remote-sensing-instruments","title":"5.4 Types of Passive Remote Sensing Instruments","text":"<p>Most passive remote sensing sensors are classified as either multispectral (MS) or hyperspectral (HS) instruments.  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#541-multispectral-sensors","title":"5.4.1 Multispectral Sensors","text":"<p>Multispectral remote sensing records data in multiple spectral bands of the electromagnetic spectrum. - The first multispectral satellite, Landsat\u2019s Multispectral Scanner (MSS), was launched in 1972. - It recorded data in four spectral bands (blue, green, red, and near-infrared), which were crucial for vegetation analysis. - Today\u2019s advanced multispectral sensors, such as Sentinel-2, provide:   - 13 spectral bands   - High revisit times   - Spatial resolution up to 10 meters </p> <p>\ud83d\udccc Multispectral satellites like Sentinel-2 have revolutionized global remote sensing by providing frequent and detailed observations of land surfaces. </p>"},{"location":"assets/lectures/lecture_1/#542-hyperspectral-sensors","title":"5.4.2 Hyperspectral Sensors","text":"<p>Hyperspectral sensors capture hundreds of narrow spectral bands, offering finer spectral resolution than multispectral sensors. - Instead of just a few bands, hyperspectral sensors collect data across the entire electromagnetic spectrum, allowing for detailed material classification. - Hyperspectral imaging is particularly useful for:   a. Identifying specific minerals, water quality, and vegetation health.   b. Detecting chemical compositions of materials.   c. Monitoring environmental changes with greater precision.  </p> <p>\ud83d\udccc Comparison of Multispectral vs. Hyperspectral Sensors: </p> Sensor Type Number of Bands Spectral Band Width Example Applications Multispectral 3-20 50-200 nm Land cover mapping, vegetation health Hyperspectral 100+ 10-20 nm Mineral identification, water quality <p>Explore Interactive Spectral Visualization: For an interactive visualization of the electromagnetic spectrum, including spectral characteristics and wavelength manipulation, visit:   Interactive EMSpectrum Tool </p>"},{"location":"assets/lectures/lecture_1/#6-resolutions-imaging-properties-6-resolutions-imaging-properties","title":"6. Resolutions - Imaging Properties {#6-resolutions-imaging-properties}","text":""},{"location":"assets/lectures/lecture_1/#61-introduction-to-resolutions","title":"6.1 Introduction to Resolutions","text":"<p>One of the first considerations when using remotely sensed data is data quality. In scientific research, good quality data must be relevant to the scale and time period of the study. To achieve this, remote sensing sensors are designed with specific applications in mind and are characterized by four key resolutions:  </p> <ol> <li>Spatial Resolution \u2013 Defines the smallest distinguishable detail in an image.  </li> <li>Temporal Resolution \u2013 Refers to how often an area is imaged.  </li> <li>Spectral Resolution \u2013 Determines the number and width of wavelength bands measured.  </li> <li>Radiometric Resolution \u2013 Defines a sensor\u2019s ability to detect differences in energy intensity.  </li> </ol> <p>Each of these resolutions impacts the type, accuracy, and usability of remote sensing data for different applications.  </p>"},{"location":"assets/lectures/lecture_1/#61-spatial-resolution-61-spatial-resolution","title":"6.1 Spatial Resolution {#61-spatial-resolution}","text":"<p>Spatial resolution refers to the ground area represented by a single pixel in an image. - A higher spatial resolution means finer details, as each pixel covers a smaller area on the ground. - A lower spatial resolution means coarser details, with each pixel covering a larger area.  </p>"},{"location":"assets/lectures/lecture_1/#611-pixels-and-image-formation","title":"6.1.1 Pixels and Image Formation","text":"<p>When a sensor collects data, it captures information from an area of the Earth's surface. - This area could be as small as a single tree or as large as an entire city. - All electromagnetic radiation (EMR) collected in this area is averaged into a single pixel value. - An image is formed when multiple pixels are collected over an area.  </p> <p>\ud83d\udccc Illustration: The concept of pixel size and spatial resolution </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#612-factors-affecting-spatial-resolution","title":"6.1.2 Factors Affecting Spatial Resolution","text":"<p>Several factors influence spatial resolution: a. Field of View (FOV) \u2013 The area observed by the sensor, determined by its viewing angle and altitude. b. Instantaneous Field of View (IFOV) \u2013 The area observed by the sensor at the moment a pixel is recorded. c. Altitude and Orbit \u2013 Satellites at higher altitudes have coarser resolution, while low-orbit sensors capture finer details.  </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#613-mixed-pixels-66-mixed-pixels","title":"6.1.3 Mixed Pixels {#66-mixed-pixels}","text":""},{"location":"assets/lectures/lecture_1/#what-are-mixed-pixels","title":"\ud83d\udd0d What Are Mixed Pixels?","text":"<p>A mixed pixel occurs when a single pixel contains signals from multiple surface types rather than representing a single, uniform feature.  </p> <p>This happens when: - The spatial resolution of the sensor is too coarse to distinguish fine details. - Different land cover types (e.g., vegetation, water, soil) are present within the same pixel area. - The transition between features (e.g., urban-rural boundaries, coastlines) is gradual rather than distinct.  </p> <p>\ud83d\udccc Illustration: Mixed Pixels in Satellite Imagery </p> <p> </p>"},{"location":"assets/lectures/lecture_1/#614-impact-of-mixed-pixels","title":"6.1.4 Impact of Mixed Pixels","text":"<p>Mixed pixels can introduce errors in remote sensing analysis, as they: a. Reduce classification accuracy, making it difficult to assign a pixel to a single land cover class. b. Cause spectral mixing, where the recorded spectral signature is an average of multiple materials. c. Affect change detection, making it harder to track specific land cover transitions.  </p>"},{"location":"assets/lectures/lecture_1/#615-trade-offs-in-spatial-resolution","title":"6.1.5 Trade-offs in Spatial Resolution","text":"<p>a. Higher spatial resolution provides detailed imagery but requires more storage and processing power. b. Lower spatial resolution is easier to process but may miss small features.  </p> <p>When choosing a sensor for an application, scientists balance detail, processing efficiency, and study area coverage.  </p>"},{"location":"assets/lectures/lecture_1/#62-temporal-resolution-62-temporal-resolution","title":"6.2 Temporal Resolution {#62-temporal-resolution}","text":"<p>Temporal resolution refers to the time interval between successive observations of the same location.  </p> <ul> <li>It can range from hours to years, depending on the application, platform and sensor.  </li> <li>It is essential for monitoring changes over time (e.g., urban growth, deforestation, climate change).  </li> </ul> <p>\ud83d\udccc Common Temporal Resolutions in Remote Sensing: </p> Application Temporal Resolution Weather Monitoring Hourly Vegetation Growth &amp; Crop Health Daily \u2013 Weekly Urban Expansion Studies Annually Climate Change Analysis Decadal"},{"location":"assets/lectures/lecture_1/#621-revisit-time","title":"6.2.1 Revisit Time","text":"<p>Revisit time is the interval between consecutive observations of the same location. - Stationary sensors (e.g., geostationary satellites) have short revisit times (seconds/minutes). - Orbiting sensors may take days or weeks to return to the same location.  </p> <p>Some satellites (e.g., Sentinel-2) are designed for high temporal resolution, ensuring frequent monitoring of Earth's surface.  </p>"},{"location":"assets/lectures/lecture_1/#63-spectral-resolution-63-spectral-resolution","title":"6.3 Spectral Resolution {#63-spectral-resolution}","text":"<p>Spectral resolution defines how a sensor detects electromagnetic radiation (EMR) across different wavelengths.  </p> <p> </p> <p>\ud83d\udccc Spectral resolution refers to: a. The number of spectral bands a sensor detects. b. The location of bands along the electromagnetic spectrum. c. The width of each spectral band (narrow vs. wide).  </p>"},{"location":"assets/lectures/lecture_1/#631-spectral-bands-and-energy-sensitivity","title":"6.3.1 Spectral Bands and Energy Sensitivity","text":"<p>Each sensor records specific wavelength ranges, which determine what features can be observed. - Shorter wavelengths (e.g., blue light) have higher energy and are easier to detect. - Longer wavelengths (e.g., thermal infrared, microwave) require larger band widths for effective observation.  </p> <p>\ud83d\udccc Example: Landsat Mission Sensors &amp; Spectral Bands </p> <p>Landsat satellites have evolved to include more spectral bands: - Landsat 1-5: Multispectral Scanner System (MSS) - Landsat 4-5: Thematic Mapper (TM) - Landsat 7: Enhanced Thematic Mapper Plus (ETM+) </p> <p>\ud83d\udccc Illustration: Spectral bands of Landsat sensors </p> <p>Sensors with higher spectral resolution capture more bands and provide richer spectral data for classification.  </p>"},{"location":"assets/lectures/lecture_1/#64-radiometric-resolution-64-radiometric-resolution","title":"6.4 Radiometric Resolution {#64-radiometric-resolution}","text":"<p>Radiometric resolution determines a sensor\u2019s ability to detect small differences in energy intensity. - Incoming photons pass through a filter, allowing only specific wavelengths to reach the detector. - The sensor assigns a digital number (DN) to each pixel, representing energy intensity.  </p>"},{"location":"assets/lectures/lecture_1/#641-bits-and-data-storage","title":"6.4.1 Bits and Data Storage","text":"<p>Radiometric resolution is measured in bits, which define the number of discernible energy levels. - Higher bit depth = greater sensitivity to subtle differences.  </p> <p>\ud83d\udccc Common Radiometric Resolutions: </p> Bit Depth Number of Discrete Levels Example Applications 8-bit 256 levels Standard satellite imagery 12-bit 4,096 levels Advanced environmental monitoring 16-bit 65,536 levels High-precision scientific analysis <p> </p> <p>The left image is 16-bit radiometric resolution (65,536 discrete shades of grey), the center image is an 8-bit radiometric resolution (256 discrete shades of grey), the right image is 4-bit radiometric resolution (16 discrete shades of grey).</p>"},{"location":"assets/lectures/lecture_1/#642-visualization-of-radiometric-resolution","title":"6.4.2 Visualization of Radiometric Resolution","text":"<p>\ud83d\udccc Illustration: Radiometric Resolution and Data Depth </p> <p> </p> <p>a. Higher radiometric resolution allows for finer distinctions in brightness, improving image quality. b. However, increasing resolution also increases data storage and processing requirements.  </p>"},{"location":"assets/lectures/lecture_1/#65-summary-choosing-the-right-resolution","title":"6.5 Summary: Choosing the Right Resolution","text":"<p>Each resolution influences how remote sensing data is collected, processed, and applied.  </p> <p>\ud83d\udccc Key Takeaways: - Spatial resolution affects detail level \u2013 Higher resolution means finer details but larger storage requirements. - Temporal resolution affects frequency of observations \u2013 Important for tracking changes over time. - Spectral resolution affects wavelength coverage \u2013 Determines how well features can be distinguished. - Radiometric resolution affects energy detection sensitivity \u2013 Impacts image clarity and depth.  </p> <p>Choosing the right sensor depends on the study's objectives and computational resources! </p>"},{"location":"assets/lectures/lecture_1/#remote-sensing-quiz","title":"\ud83c\udfaf Remote Sensing Quiz","text":""},{"location":"assets/lectures/lecture_1/#identify-the-object-in-the-satellite-image","title":"\ud83d\udef0\ufe0f Identify the Object in the Satellite Image","text":"<p>The following image is a satellite image taken from Landsat-8, orbiting 700 km above the ground.  </p>"},{"location":"assets/lectures/lecture_1/#can-you-identify-what-is-inside-the-red-circle","title":"\ud83d\udd0d Can you identify what is inside the red circle?","text":""},{"location":"assets/projects/bare_soil/","title":"\ud83c\udf0d Monitoring Bare-Soil Exposure Using Satellite Data","text":""},{"location":"assets/projects/bare_soil/#basic-info","title":"\ud83d\udccc Basic Info","text":"<p>The bare-soil marker is used to detect areas with exposed bare soil, which can result from: - Recent plowing or tillage activities. - Harvesting, leaving non-photosynthetic vegetation residues. - Natural vegetation drying, revealing soil due to seasonal or climatic conditions.  </p> <p>While plowing or harvesting events themselves cannot be directly observed in satellite imagery, their effects are detectable. By analyzing Sentinel-2 optical data, we can classify areas with bare soil based on spectral characteristics.  </p> <p>\ud83d\udccc Key Observations: - Bare soil appears brownish or grayish in false-color Sentinel-2 images. - Vegetation presence is indicated by red tones in false-color imagery. - The bare-soil marker assigns a probability score (0 to 1) for each Sentinel-2 observation. - Observations with probability above a defined threshold (e.g., 0.8) are classified as bare-soil events.  </p>"},{"location":"assets/projects/bare_soil/#further-info","title":"\ud83d\udcca Further Info","text":"<p>The timing of bare-soil exposure depends on: - \ud83c\udf3e Crop type being cultivated. - \ud83d\ude9c Farming practices such as tillage and harvesting schedules.  </p> <p>By analyzing temporal distributions of detected bare-soil observations, we can distinguish different land-use patterns.  </p> <p>\ud83d\udef0\ufe0f Example Case: - Cornfields in Slovenia exhibit bare soil from early January to June and again after mid-October. - Summer barley fields show exposed bare soil earlier in the year compared to winter barley due to different sowing periods. - Vegetable fields display bare-soil detections throughout the year, reflecting multiple sowing and harvesting cycles. - Permanent meadows are expected to remain vegetated year-round, meaning any bare-soil detection could indicate land-use inconsistencies.  </p> <p>\ud83d\udccc Visualization: - \ud83d\udcca Time-series analysis of NDVI (green) vs. bare-soil probability (orange). - \ud83d\uddbc\ufe0f Sentinel-2 false-color images showing bare-soil classification over time. - \ud83d\udd0d Bare-soil masks overlaid on true-color Sentinel-2 images to confirm detections.  </p>"},{"location":"assets/projects/bare_soil/#marker-output","title":"\ud83d\udccc Marker Output","text":"<p>This analysis generates: \ud83d\udccd Detected bare-soil events, marking periods of exposed soil. \ud83d\udccd Probability values for each observation. \ud83d\udccd Temporal distribution plots to assess land-use patterns.  </p>"},{"location":"assets/projects/bare_soil/#user-controlled-parameters","title":"\ud83d\udd27 User-Controlled Parameters","text":"<p>To fine-tune detection accuracy, users can modify: - Threshold probability for bare-soil classification (e.g., 0.8). - Smoothing filters to minimize noise in spectral changes. - Time-window constraints to detect seasonal land-use trends.  </p>"},{"location":"assets/projects/bare_soil/#data-sources-methods","title":"\ud83d\udce1 Data Sources &amp; Methods","text":"<p>This project integrates optical and environmental data sources: - \ud83d\udef0\ufe0f Sentinel-2 MSI \u2013 Multispectral analysis for vegetation indices and soil exposure detection. - \ud83c\udf0d Copernicus Land Monitoring Services \u2013 Baseline land cover classification. - \ud83d\udccf In situ measurements \u2013 Spectroradiometer data for validation and calibration.  </p> <p>\ud83d\udccc Final Deliverables: - \ud83d\udcca Maps showing temporal changes in bare-soil exposure. - \ud83d\udcc8 Automated processing script for Sentinel-2-based detection. - \ud83d\udcd6 Report analyzing trends across different crop types and farming systems.  </p> <p>\ud83d\ude80 This project enhances agricultural monitoring by providing insights into soil exposure, land-use patterns, and farming activity trends. \ud83d\udcc5 Expected completion: Summer 2025. </p> <p>\ud83d\udccc Back to Projects </p>"},{"location":"assets/projects/beekeeping/","title":"\ud83d\udc1d Mobile Beekeeping Optimization \u2013 Nowos\u0105decki County","text":""},{"location":"assets/projects/beekeeping/#1-project-objective","title":"1. Project Objective","text":"<p>This project develops data-driven recommendations for mobile beekeeping based on nectar-producing plant distribution. \u2705 Identifying optimal locations for relocating beehives \u2705 Determining flowering periods of key honey plants \u2705 Assessing meteorological conditions affecting pollination </p>"},{"location":"assets/projects/beekeeping/#2-data-sources","title":"2. Data Sources","text":"<p>\ud83d\udce1 Sentinel-2 (optical) \u2013 NDVI, EVI for flowering detection \ud83d\udce1 Sentinel-1 (SAR) \u2013 Detecting vegetation density changes \ud83d\udccd Copernicus Land Monitoring Service \u2013 High-Resolution Land Cover Data \ud83c\udf26 Meteorological data (ECMWF/ERA5) \u2013 Temperature, precipitation  </p>"},{"location":"assets/projects/beekeeping/#3-analysis-methods","title":"3. Analysis Methods","text":"<p>\ud83d\udd39 Time-series analysis of flowering trends \ud83d\udd39 Generate heatmaps of optimal beekeeping locations \ud83d\udd39 Integrate environmental risk factors (drought, frost, pesticides) </p> <p>\ud83d\udccc In situ data collection is required, either through field-based spectral analysis (spectroradiometer, drone imagery) or via beekeeping associations, agricultural organizations, and meteorological agencies.  </p>"},{"location":"assets/projects/beekeeping/#4-expected-outcomes","title":"4. Expected Outcomes","text":"<p>\u2705 Monthly calendar for optimal hive relocation \u2705 Spatial maps of nectar-rich zones \u2705 Recommendations for sustainable beekeeping strategies </p> <p>\ud83d\udccc Back to Projects </p>"},{"location":"assets/projects/chl_a/","title":"\ud83c\udf0a Monitoring Chlorophyll Levels in Solina Reservoir Using Satellite Data","text":""},{"location":"assets/projects/chl_a/#basic-info","title":"\ud83d\udccc Basic Info","text":"<p>Monitoring chlorophyll concentrations in inland water bodies is essential for understanding water quality, algal blooms, and ecological changes. This project focuses on using multi-source satellite data and in situ measurements to track chlorophyll-a levels in the Solina Reservoir, one of Poland\u2019s largest artificial lakes.  </p> <p>The project integrates: - Sentinel-3 OLCI (Ocean and Land Colour Instrument) \u2013 Daily revisit time, enabling continuous monitoring. - Sentinel-2 MSI (Multispectral Instrument) \u2013 Higher spatial resolution (5-day revisit time), complementing Sentinel-3 observations. - In situ measurements \u2013 Collected using field spectroradiometers and water sampling for validation and model calibration.  </p>"},{"location":"assets/projects/chl_a/#further-info","title":"\ud83d\udcca Further Info","text":"<p>Chlorophyll-a is a key indicator of phytoplankton biomass and can be used to detect eutrophication levels in freshwater reservoirs. By combining high-temporal-resolution Sentinel-3 data with high-spatial-resolution Sentinel-2 imagery, we can: \u2714\ufe0f Improve the accuracy of chlorophyll-a concentration estimates. \u2714\ufe0f Analyze seasonal and spatial variations of water quality in Solina. \u2714\ufe0f Detect algal bloom events and their progression over time.  </p> <p>\ud83d\udccc Key Methodology: 1. Preprocessing Sentinel-3 OLCI data \u2013 Chlorophyll index retrieval using band ratios and bio-optical models. 2. Integration with Sentinel-2 MSI \u2013 Higher spatial resolution data to refine Sentinel-3 results. 3. Validation with in situ data \u2013 Using field spectroradiometer readings and laboratory analysis of water samples. 4. Time-series analysis \u2013 Detecting chlorophyll trends over different seasons.  </p> <p>\ud83d\udef0\ufe0f Example Case: - High chlorophyll-a levels in summer months due to increased nutrient load and higher temperatures. - Lower concentrations in winter, with stable water conditions. - Sentinel-3 provides daily variability, while Sentinel-2 enhances detailed spatial analysis.  </p>"},{"location":"assets/projects/chl_a/#project-output","title":"\ud83d\udccc Project Output","text":"<p>This study will produce: \ud83d\udccd Chlorophyll concentration maps for Solina Reservoir. \ud83d\udccd Time-series analysis showing chlorophyll trends over time. \ud83d\udccd Comparison between Sentinel-3, Sentinel-2, and in situ measurements for accuracy assessment.  </p>"},{"location":"assets/projects/chl_a/#user-controlled-parameters","title":"\ud83d\udd27 User-Controlled Parameters","text":"<p>Users can fine-tune: - Thresholds for chlorophyll detection (e.g., eutrophication alert levels). - Integration models between Sentinel-2 and Sentinel-3 data. - Temporal aggregation to minimize noise in satellite-derived results.  </p>"},{"location":"assets/projects/chl_a/#data-sources-methods","title":"\ud83d\udce1 Data Sources &amp; Methods","text":"<p>This project combines remote sensing and field measurements: - \ud83d\udef0\ufe0f Sentinel-3 OLCI \u2013 Daily revisit time, ocean color-based chlorophyll detection. - \ud83d\udef0\ufe0f Sentinel-2 MSI \u2013 5-day revisit time, high-resolution water quality monitoring. - \ud83c\udf0d Copernicus Water Quality Services \u2013 Reference chlorophyll datasets. - \ud83d\udccf In situ spectroradiometer measurements \u2013 Ground truth validation.  </p> <p>\ud83d\udccc Final Deliverables: - Chlorophyll concentration maps and trends. - Automated processing script for Sentinel-based monitoring. - Report on water quality changes and potential eutrophication risks.  </p> <p>\ud83d\ude80 This project will contribute to sustainable water resource management by providing an advanced monitoring system for chlorophyll levels in Solina Reservoir. \ud83d\udcc5 Expected completion: Summer 2025. </p> <p>\ud83d\udccc Back to Projects </p>"},{"location":"assets/projects/mining_sites/","title":"\ud83c\udfd7\ufe0f Open-Pit Mining Detection &amp; Monitoring","text":""},{"location":"assets/projects/mining_sites/#1-project-objective","title":"1. Project Objective","text":"<p>This project aims to detect and monitor open-pit mining sites using Sentinel-1 and Sentinel-2. </p> <p>\u2705 Identifying active and abandoned mining areas. \u2705 Tracking year-over-year excavation changes. \u2705 Assessing environmental impact (vegetation loss, water contamination, garbage dumps).  </p>"},{"location":"assets/projects/mining_sites/#2-data-sources","title":"2. Data Sources","text":"<p>\ud83d\udce1 Sentinel-2 (optical) \u2013 NDVI, NDBI, MNDWI for land cover classification \ud83d\udce1 SPOT (VHR) \u2013 object detection \ud83d\udce1 Sentinel-1 (SAR) \u2013 Surface deformation and excavation monitoring \ud83d\udccd Mining permits database \u2013 Validating legal vs. illegal operations  </p> <p>\ud83d\udccc In situ data collection is required, either through direct spectral measurements (spectroradiometer, drone imaging) or via geological institutions, mining companies, or environmental agencies.  </p>"},{"location":"assets/projects/mining_sites/#3-analysis-methods","title":"3. Analysis Methods","text":"<p>\ud83d\udd39 Compare multi-temporal Sentinel-2 images with VHR SPOT data to detect land cover changes \ud83d\udd39 Analyze radar backscatter variations in mining zones \ud83d\udd39 Generate risk assessment maps </p>"},{"location":"assets/projects/mining_sites/#4-expected-outcomes","title":"4. Expected Outcomes","text":"<p>\u2705 Maps highlighting newly excavated areas \u2705 Detection of unauthorized mining sites \u2705 Environmental impact analysis of mining expansion </p> <p>\ud83d\udccc Back to Projects </p>"},{"location":"assets/projects/soil_moisture/","title":"\ud83c\udf31 Soil Moisture Monitoring Using Remote Sensing","text":""},{"location":"assets/projects/soil_moisture/#1-project-objective","title":"1. Project Objective","text":"<p>This project will analyze soil moisture levels using Sentinel-1 and Sentinel-2 data.  </p> <p>Key goals include:  </p> <p>\u2705 Identifying seasonal variations in soil moisture. \u2705 Comparing optical vs. SAR-based moisture estimation. \u2705 Mapping moisture trends across agricultural areas. \u2705 Correlating satellite indices with field (IoT) measurements.  </p>"},{"location":"assets/projects/soil_moisture/#2-data-sources","title":"2. Data Sources","text":"<p>\ud83d\udce1 Sentinel-1 (SAR) \u2013 Backscatter intensity analysis \ud83d\udce1 Sentinel-2 (optical) \u2013 NDWI, MSI for moisture detection \ud83c\udf26 Meteorological data \u2013 Precipitation, soil temperature  </p> <p>\ud83d\udccc In situ data collection is required, either by direct field measurements (spectroradiometer, soil probes) or by obtaining soil moisture data from agriculture institutes, meteorological agencies, or research organizations.  </p>"},{"location":"assets/projects/soil_moisture/#3-analysis-methods","title":"3. Analysis Methods","text":"<p>\ud83d\udd39 Extract NDWI and MSI indices for soil moisture estimation \ud83d\udd39 Analyze Sentinel-1 backscatter differences \ud83d\udd39 Compare trends over multiple years (2015-present) </p>"},{"location":"assets/projects/soil_moisture/#4-expected-outcomes","title":"4. Expected Outcomes","text":"<p>\u2705 Maps showing moisture distribution over time \u2705 Insights into climate effects on soil conditions \u2705 Correlation of moisture indices with weather patterns </p> <p>\ud83d\udccc Back to Projects </p>"},{"location":"assets/projects/soil_tillage/","title":"\ud83c\udf3e Monitoring Soil Tillage Using Satellite Data","text":""},{"location":"assets/projects/soil_tillage/#basic-info","title":"\ud83d\udccc Basic Info","text":"<p>Detecting soil tillage activities is crucial for effective agricultural land management. Monitoring these activities helps in: - \u2705 Assessing field maintenance and soil preparation for cultivation. - \u2705 Ensuring compliance with environmental regulations, especially regarding subsidy programs. - \u2705 Tracking soil condition and erosion risks resulting from tillage practices.  </p> <p>Satellite-based observation provides an efficient way to identify when and where soil tillage occurs. While direct observation of tillage is challenging, its effects on the land surface can be detected through spectral and radar signal changes. By analyzing Sentinel-2 optical data and Sentinel-1 SAR backscatter, we can infer tillage events based on changes in vegetation cover and surface roughness.  </p>"},{"location":"assets/projects/soil_tillage/#further-info","title":"\ud83d\udcca Further Info","text":"<p>Tillage significantly alters the land surface, leading to: \u2714\ufe0f Increase in bare-soil probability due to reduced vegetation cover. \u2714\ufe0f Decrease in NDVI (Normalized Difference Vegetation Index), indicating soil exposure. \u2714\ufe0f Changes in SAR backscatter, revealing surface roughness variations.  </p> <p>The combination of bare-soil probability increase and NDVI decline provides an effective method for detecting tillage events. \ud83d\udccc Key methodology: - Start of tillage is marked by a sudden rise in bare-soil probability. - End of tillage is defined by the stabilization of this probability. - Inverse correlation exists between bare-soil probability and NDVI\u2014when bare soil increases, NDVI decreases.  </p> <p>\ud83d\udef0\ufe0f Example Case: A cornfield vegetated until late September, then tilled in early October, would exhibit: \u2705 A sharp increase in bare-soil probability, confirming tillage activity. \u2705 A notable drop in NDVI, signaling loss of vegetation cover. \u2705 A SAR signal change in Sentinel-1, indicating surface roughness modifications.  </p>"},{"location":"assets/projects/soil_tillage/#marker-output","title":"\ud83d\udccc Marker Output","text":"<p>This analysis provides: \ud83d\udccd Detected tillage events \u2013 specific dates when soil was tilled. \ud83d\udccd Bare-soil probability values for each detected event. \ud83d\udccd NDVI trend analysis confirming vegetation loss.  </p>"},{"location":"assets/projects/soil_tillage/#user-controlled-parameters","title":"\ud83d\udd27 User-Controlled Parameters","text":"<p>Users can adjust the model sensitivity to reduce false positives and false negatives by modifying: - Threshold for bare-soil probability increase to validate tillage detection. - Minimum NDVI drop required for a confirmed event. - Temporal smoothing filters to reduce noise in data.  </p>"},{"location":"assets/projects/soil_tillage/#data-sources-methods","title":"\ud83d\udce1 Data Sources &amp; Methods","text":"<p>This project utilizes a combination of optical, radar, and environmental datasets: - \ud83d\udef0\ufe0f Sentinel-2 MSI \u2013 NDVI and spectral reflectance analysis. - \ud83d\udce1 Sentinel-1 SAR \u2013 Backscatter changes indicating surface disturbance. - \ud83c\udf0d Copernicus Land Monitoring Services \u2013 Reference land cover classification. - \ud83d\udccf In situ data collection \u2013 Ground truth measurements using field spectroradiometers or farmer reports.  </p> <p>\ud83d\udccc Final Deliverables: - Interactive maps displaying historical and current tillage patterns. - Automated script for tillage event detection using satellite data. - Analytical report correlating tillage trends with land management practices.  </p> <p>\ud83d\ude80 This project contributes to precision agriculture by providing reliable insights into soil tillage and land preparation activities. \ud83d\udcc5 Expected completion: Summer 2025. </p> <p>\ud83d\udccc Back to Projects </p>"},{"location":"assets/projects/water_quality/","title":"\ud83c\udf0a Water Quality Assessment \u2013 Dobczyckie Lake","text":""},{"location":"assets/projects/water_quality/#1-project-objective","title":"1. Project Objective","text":"<p>This project aims to assess water quality in Dobczyckie Lake using Sentinel-2 data and in situ measurements. Key aspects include: \u2705 Monitoring chlorophyll-a (Chl-a), turbidity, and suspended matter (TSM). \u2705 Correlating satellite indices with field (buoy) measurements. \u2705 Generating spatial maps of water quality over time.  </p>"},{"location":"assets/projects/water_quality/#2-data-sources","title":"2. Data Sources","text":"<p>\ud83d\udce1 Sentinel-2 (optical) \u2013 NDWI, Chl-a, TSM, etc. \ud83d\udccd In situ measurements \u2013 Chlorophyll, turbidity, surface temperature \ud83c\udf26 Meteorological data \u2013 ECMWF/ERA5 precipitation, temperature, etc.</p> <p>\ud83d\udccc In situ data collection is required, either by direct measurements (using a spectroradiometer) or by obtaining datasets from third-party institutions (environmental agencies, research centers).  </p>"},{"location":"assets/projects/water_quality/#3-analysis-methods","title":"3. Analysis Methods","text":"<p>\ud83d\udd39 Retrieve Sentinel-2 images and apply cloud masking \ud83d\udd39 Extract water quality indices and compare with field data \ud83d\udd39 Create water quality maps for different time periods  </p>"},{"location":"assets/projects/water_quality/#4-expected-outcomes","title":"4. Expected Outcomes","text":"<p>\u2705 Time-series analysis of water quality changes \u2705 Maps of turbidity, chlorophyll, and other spectral indices \u2705 Final report with recommendations for water monitoring </p> <p>\ud83d\udccc Back to Projects </p>"},{"location":"assets/projects/wheat_monitoring/","title":"\ud83c\udf3e Winter Wheat Monitoring \u2013 Kazimierza County (2015-Present)","text":""},{"location":"assets/projects/wheat_monitoring/#1-project-objective","title":"1. Project Objective","text":"<p>This project will analyze winter wheat cultivation trends using Sentinel-1 and Sentinel-2 imagery. \u2705 Mapping wheat fields and expansion trends since 2015 \u2705 Assessing crop biomass and vegetation stress \u2705 Correlating yield with Sentinel-2 NDVI/EVI </p>"},{"location":"assets/projects/wheat_monitoring/#2-data-sources","title":"2. Data Sources","text":"<p>\ud83d\udce1 Sentinel-1 (SAR) \u2013 Detecting vegetation density changes \ud83d\udce1 Sentinel-2 (optical) \u2013 NDVI, EVI, SWIR-based biomass indices \ud83d\udccd Agricultural statistics \u2013 Historical yield data \ud83c\udf26 Meteorological data \u2013 Precipitation, drought records  </p>"},{"location":"assets/projects/wheat_monitoring/#3-analysis-methods","title":"3. Analysis Methods","text":"<p>\ud83d\udd39 Time-series analysis of wheat growth cycles \ud83d\udd39 Compare NDVI/EVI trends with reported yields \ud83d\udd39 Assess fertilization strategies vs. biomass productivity </p> <p>\ud83d\udccc In situ data collection is required, either through spectroradiometer-based field measurements or via agricultural organizations, farmer reports, and research institutions.  </p>"},{"location":"assets/projects/wheat_monitoring/#4-expected-outcomes","title":"4. Expected Outcomes","text":"<p>\u2705 Year-over-year changes in wheat cultivation area \u2705 Insights into biomass stress and fertilization effectiveness \u2705 Correlation of NDVI/EVI values with wheat yields </p> <p>\ud83d\udccc Back to Projects </p>"}]}